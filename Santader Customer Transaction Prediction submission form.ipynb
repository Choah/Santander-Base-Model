{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "In this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Baseline Model\n",
    "\n",
    "\n",
    "**Description of data**\n",
    "\n",
    "- Number of input variables(var_0, var_1, ... , var_199) is 200, each input variable data type is 'float' and anonymized.\n",
    "- Target variable is binary variable consisting of 0, 1. \n",
    "- number of Train data rows  =  number of Train data rows\n",
    "\n",
    "\n",
    "**Contents**\n",
    "\n",
    "- EDA\n",
    "- Data preprocessing \n",
    "- feature engineering\n",
    "- Select input variables highly related to output variable\n",
    "- Scaling \n",
    "- Split the data(train,test)\n",
    "- Solution of serious imbalance problem in Y variable ex.Oversampling,Undersampling,Smote\n",
    "- Modeling\n",
    "- Validation\n",
    "- Generate prediction value and submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Exclude error message \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Data analysis tool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import ks_2samp\n",
    "import time\n",
    "\n",
    "# Machine Learning tool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#!pip install xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# Visualization tool\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "from matplotlib import rc, font_manager\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "font_location = 'C:/Windows/Fonts/malgunbd.ttf' # 폰트 설정\n",
    "font_name = fm.FontProperties(fname = font_location).get_name()\n",
    "mpl.rc('font', family = font_name)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "seed = 110\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 202)\n",
      "(200000, 201)\n",
      "(200000, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Data/train.csv', engine='python', encoding='UTF-8')\n",
    "test = pd.read_csv('Data/test.csv', engine='python', encoding='UTF-8')\n",
    "submission = pd.read_csv('Data/sample_submission.csv', engine='python', encoding='UTF-8')\n",
    "\n",
    "print(train.shape) # (200000, 202) / trainset has target(Y) variable\n",
    "print(test.shape) # (200000, 201) / testset does not have target(Y) variable \n",
    "print(submission.shape) # (200000, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  target\n",
       "0  test_0       0\n",
       "1  test_1       0\n",
       "2  test_2       0\n",
       "3  test_3       0\n",
       "4  test_4       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "submission form = {first column : 'ID_code', second_column = 'target'}\n",
    "'''\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179902</td>\n",
       "      <td>0.89951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20098</td>\n",
       "      <td>0.10049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency    ratio\n",
       "0     179902  0.89951\n",
       "1      20098  0.10049"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Target == 0) ratio : 89.951% / (Target == 1) ratio : 10.049%  \n",
    "# There is series imbalance between (Target == 0) and (Target == 1)\n",
    "\n",
    "frequency = train['target'].value_counts(normalize = False)\n",
    "ratio = train['target'].value_counts(normalize = True)\n",
    "pd.DataFrame({'frequency' : frequency, 'ratio' : ratio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18d2fda65f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'target', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 201 entries, ID_code to var_199\n",
      "dtypes: float64(200), object(1)\n",
      "memory usage: 306.7+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison Train data variable with Test data variable  \n",
    "\n",
    "- Train, Test 는 동일 집단에서 샘플링 된 것 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "var_list = list(train.columns[2:])\n",
    "\n",
    "for var in var_list:\n",
    "    sns.distplot(train[var])\n",
    "    sns.distplot(test[var])\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how much they(trainset and testset) resemble each other ####\n",
    "\n",
    "-> Quentifing the resemblence between train variable distribution test variables distribution\n",
    "\n",
    "* simple function using criteria \n",
    "* Kolmogorov-Smirnov Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple function using criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>7.567236</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>1.235070</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>3.970500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>6.618800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>7.629600</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>8.584425</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>11.150600</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0      var_1      var_2      var_3      var_4      var_5  \\\n",
       "mean  10.679914  -1.627622  10.715192   6.796529  11.078333  -5.065317   \n",
       "std    3.040051   4.050044   2.640894   2.043319   1.623150   7.863267   \n",
       "min    0.408400 -15.043400   2.117100  -0.040200   5.074800 -32.562600   \n",
       "25%    8.453850  -4.740025   8.722475   5.254075   9.883175 -11.200350   \n",
       "50%   10.524750  -1.608050  10.580000   6.825000  11.108250  -4.833150   \n",
       "75%   12.758200   1.358625  12.516700   8.324100  12.261125   0.924800   \n",
       "max   20.315000  10.376800  19.353000  13.188300  16.671400  17.251600   \n",
       "\n",
       "         var_6      var_7      var_8      var_9    ...        var_190  \\\n",
       "mean  5.408949  16.545850   0.284162   7.567236    ...       3.234440   \n",
       "std   0.866607   3.418076   3.332634   1.235070    ...       4.559922   \n",
       "min   2.347300   5.349700 -10.505500   3.970500    ...     -14.093300   \n",
       "25%   4.767700  13.943800  -2.317800   6.618800    ...      -0.058825   \n",
       "50%   5.385100  16.456800   0.393700   7.629600    ...       3.203600   \n",
       "75%   6.003000  19.102900   2.937900   8.584425    ...       6.406200   \n",
       "max   8.447700  27.691800  10.151300  11.150600    ...      18.440900   \n",
       "\n",
       "        var_191   var_192    var_193    var_194   var_195    var_196  \\\n",
       "mean   7.438408  1.927839   3.331774  17.993784 -0.142088   2.303335   \n",
       "std    3.023272  1.478423   3.992030   3.135162  1.429372   5.454369   \n",
       "min   -2.691700 -3.814500 -11.783400   8.694400 -5.261000 -14.209600   \n",
       "25%    5.157400  0.889775   0.584600  15.629800 -1.170700  -1.946925   \n",
       "50%    7.347750  1.901300   3.396350  17.957950 -0.172700   2.408900   \n",
       "75%    9.512525  2.949500   6.205800  20.396525  0.829600   6.556725   \n",
       "max   16.716500  8.402400  18.281800  27.928800  4.272900  18.321500   \n",
       "\n",
       "        var_197    var_198    var_199  \n",
       "mean   8.908158  15.870720  -3.326537  \n",
       "std    0.921625   3.010945  10.438015  \n",
       "min    5.960600   6.299300 -38.852800  \n",
       "25%    8.252800  13.829700 -11.208475  \n",
       "50%    8.888200  15.934050  -2.819550  \n",
       "75%    9.593300  18.064725   4.836800  \n",
       "max   12.000400  26.079100  28.500700  \n",
       "\n",
       "[7 rows x 200 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_describe = pd.DataFrame(train.describe()).iloc[1:,1:] # remove target varible, and count row\n",
    "train_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.658737</td>\n",
       "      <td>-1.624244</td>\n",
       "      <td>10.707452</td>\n",
       "      <td>6.788214</td>\n",
       "      <td>11.076399</td>\n",
       "      <td>-5.050558</td>\n",
       "      <td>5.415164</td>\n",
       "      <td>16.529143</td>\n",
       "      <td>0.277135</td>\n",
       "      <td>7.569407</td>\n",
       "      <td>...</td>\n",
       "      <td>3.189766</td>\n",
       "      <td>7.458269</td>\n",
       "      <td>1.925944</td>\n",
       "      <td>3.322016</td>\n",
       "      <td>17.996967</td>\n",
       "      <td>-0.133657</td>\n",
       "      <td>2.290899</td>\n",
       "      <td>8.912428</td>\n",
       "      <td>15.869184</td>\n",
       "      <td>-3.246342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.036716</td>\n",
       "      <td>4.040509</td>\n",
       "      <td>2.633888</td>\n",
       "      <td>2.052724</td>\n",
       "      <td>1.616456</td>\n",
       "      <td>7.869293</td>\n",
       "      <td>0.864686</td>\n",
       "      <td>3.424482</td>\n",
       "      <td>3.333375</td>\n",
       "      <td>1.231865</td>\n",
       "      <td>...</td>\n",
       "      <td>4.551239</td>\n",
       "      <td>3.025189</td>\n",
       "      <td>1.479966</td>\n",
       "      <td>3.995599</td>\n",
       "      <td>3.140652</td>\n",
       "      <td>1.429678</td>\n",
       "      <td>5.446346</td>\n",
       "      <td>0.920904</td>\n",
       "      <td>3.008717</td>\n",
       "      <td>10.398589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.188700</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.355200</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>5.484400</td>\n",
       "      <td>-27.767000</td>\n",
       "      <td>2.216400</td>\n",
       "      <td>5.713700</td>\n",
       "      <td>-9.956000</td>\n",
       "      <td>4.243300</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.407000</td>\n",
       "      <td>-3.340900</td>\n",
       "      <td>-11.413100</td>\n",
       "      <td>9.382800</td>\n",
       "      <td>-4.911900</td>\n",
       "      <td>-13.944200</td>\n",
       "      <td>6.169600</td>\n",
       "      <td>6.584000</td>\n",
       "      <td>-39.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.442975</td>\n",
       "      <td>-4.700125</td>\n",
       "      <td>8.735600</td>\n",
       "      <td>5.230500</td>\n",
       "      <td>9.891075</td>\n",
       "      <td>-11.201400</td>\n",
       "      <td>4.772600</td>\n",
       "      <td>13.933900</td>\n",
       "      <td>-2.303900</td>\n",
       "      <td>6.623800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095000</td>\n",
       "      <td>5.166500</td>\n",
       "      <td>0.882975</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>15.634775</td>\n",
       "      <td>-1.160700</td>\n",
       "      <td>-1.948600</td>\n",
       "      <td>8.260075</td>\n",
       "      <td>13.847275</td>\n",
       "      <td>-11.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.513800</td>\n",
       "      <td>-1.590500</td>\n",
       "      <td>10.560700</td>\n",
       "      <td>6.822350</td>\n",
       "      <td>11.099750</td>\n",
       "      <td>-4.834100</td>\n",
       "      <td>5.391600</td>\n",
       "      <td>16.422700</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>7.632000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162400</td>\n",
       "      <td>7.379000</td>\n",
       "      <td>1.892600</td>\n",
       "      <td>3.428500</td>\n",
       "      <td>17.977600</td>\n",
       "      <td>-0.162000</td>\n",
       "      <td>2.403600</td>\n",
       "      <td>8.892800</td>\n",
       "      <td>15.943400</td>\n",
       "      <td>-2.725950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.739600</td>\n",
       "      <td>1.343400</td>\n",
       "      <td>12.495025</td>\n",
       "      <td>8.327600</td>\n",
       "      <td>12.253400</td>\n",
       "      <td>0.942575</td>\n",
       "      <td>6.005800</td>\n",
       "      <td>19.094550</td>\n",
       "      <td>2.930025</td>\n",
       "      <td>8.584825</td>\n",
       "      <td>...</td>\n",
       "      <td>6.336475</td>\n",
       "      <td>9.531100</td>\n",
       "      <td>2.956000</td>\n",
       "      <td>6.174200</td>\n",
       "      <td>20.391725</td>\n",
       "      <td>0.837900</td>\n",
       "      <td>6.519800</td>\n",
       "      <td>9.595900</td>\n",
       "      <td>18.045200</td>\n",
       "      <td>4.935400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.323400</td>\n",
       "      <td>9.385100</td>\n",
       "      <td>18.714100</td>\n",
       "      <td>13.142000</td>\n",
       "      <td>16.037100</td>\n",
       "      <td>17.253700</td>\n",
       "      <td>8.302500</td>\n",
       "      <td>28.292800</td>\n",
       "      <td>9.665500</td>\n",
       "      <td>11.003600</td>\n",
       "      <td>...</td>\n",
       "      <td>20.359000</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.005000</td>\n",
       "      <td>17.632600</td>\n",
       "      <td>27.947800</td>\n",
       "      <td>4.545400</td>\n",
       "      <td>15.920700</td>\n",
       "      <td>12.275800</td>\n",
       "      <td>26.538400</td>\n",
       "      <td>27.907400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0      var_1      var_2      var_3      var_4      var_5  \\\n",
       "mean  10.658737  -1.624244  10.707452   6.788214  11.076399  -5.050558   \n",
       "std    3.036716   4.040509   2.633888   2.052724   1.616456   7.869293   \n",
       "min    0.188700 -15.043400   2.355200  -0.022400   5.484400 -27.767000   \n",
       "25%    8.442975  -4.700125   8.735600   5.230500   9.891075 -11.201400   \n",
       "50%   10.513800  -1.590500  10.560700   6.822350  11.099750  -4.834100   \n",
       "75%   12.739600   1.343400  12.495025   8.327600  12.253400   0.942575   \n",
       "max   22.323400   9.385100  18.714100  13.142000  16.037100  17.253700   \n",
       "\n",
       "         var_6      var_7     var_8      var_9    ...        var_190  \\\n",
       "mean  5.415164  16.529143  0.277135   7.569407    ...       3.189766   \n",
       "std   0.864686   3.424482  3.333375   1.231865    ...       4.551239   \n",
       "min   2.216400   5.713700 -9.956000   4.243300    ...     -14.093300   \n",
       "25%   4.772600  13.933900 -2.303900   6.623800    ...      -0.095000   \n",
       "50%   5.391600  16.422700  0.372000   7.632000    ...       3.162400   \n",
       "75%   6.005800  19.094550  2.930025   8.584825    ...       6.336475   \n",
       "max   8.302500  28.292800  9.665500  11.003600    ...      20.359000   \n",
       "\n",
       "        var_191   var_192    var_193    var_194   var_195    var_196  \\\n",
       "mean   7.458269  1.925944   3.322016  17.996967 -0.133657   2.290899   \n",
       "std    3.025189  1.479966   3.995599   3.140652  1.429678   5.446346   \n",
       "min   -2.407000 -3.340900 -11.413100   9.382800 -4.911900 -13.944200   \n",
       "25%    5.166500  0.882975   0.587600  15.634775 -1.160700  -1.948600   \n",
       "50%    7.379000  1.892600   3.428500  17.977600 -0.162000   2.403600   \n",
       "75%    9.531100  2.956000   6.174200  20.391725  0.837900   6.519800   \n",
       "max   16.716500  8.005000  17.632600  27.947800  4.545400  15.920700   \n",
       "\n",
       "        var_197    var_198    var_199  \n",
       "mean   8.912428  15.869184  -3.246342  \n",
       "std    0.920904   3.008717  10.398589  \n",
       "min    6.169600   6.584000 -39.457800  \n",
       "25%    8.260075  13.847275 -11.124000  \n",
       "50%    8.892800  15.943400  -2.725950  \n",
       "75%    9.595900  18.045200   4.935400  \n",
       "max   12.275800  26.538400  27.907400  \n",
       "\n",
       "[7 rows x 200 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_describe = pd.DataFrame(test.describe()).iloc[1:,:] # remove count row\n",
    "test_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([4], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([4], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([4], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([1], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64),\n",
       "       array([5], dtype=int64), array([5], dtype=int64)], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def measure_resemble_train_test(train_d,test_d,criteria=0.1):\n",
    "    '''\n",
    "    If (data_train values - data_test values) <  criteria,\n",
    "    then We can infer data_train values are close to data_test values ranging from criteria\n",
    "    \n",
    "    Criteria is 0.1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    k = list()\n",
    "    for i in range(test_d.shape[1]):\n",
    "        a = ((train_d - test_d).iloc[[0,1,3,4,5],:] < criteria).iloc[:,i:i+1].sum().values \n",
    "        k.append(a)\n",
    "    return pd.Series(k)\n",
    "\n",
    "mr = measure_resemble_train_test(train_d = train_describe,test_d = test_describe,criteria = 0.1).values.flatten()\n",
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr2 = list()\n",
    "for i in range(len(mr)):\n",
    "    mr_sub = mr[i][0]\n",
    "    mr2.append(mr_sub)\n",
    "mr2\n",
    "\n",
    "cri = [x == 5 for x in mr2]\n",
    "cri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 98% variables of X variables can meet simple function using criteria(0.1)\n",
    "sum(cri) / len(cri) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Komolgrov_Smirnov Test\n",
    "\n",
    " In K-S test, the distribution is assumed to be continuous and K-S test is the two-sided test.</bs>\n",
    "\n",
    " If the K-S statistic is small or the p-value is high, then can't reject the hypothesis that the distribution of the two samples are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ks_2sampResult(statistic=0.004325000000000023, pvalue=0.04731919978574686), Ks_2sampResult(statistic=0.003034999999999982, pvalue=0.31522455100688157), Ks_2sampResult(statistic=0.003689999999999971, pvalue=0.1310171063142887), Ks_2sampResult(statistic=0.0037950000000000483, pvalue=0.11195859358100853), Ks_2sampResult(statistic=0.003210000000000046, pvalue=0.2537769888530248), Ks_2sampResult(statistic=0.0017399999999999638, pvalue=0.9223684472570001), Ks_2sampResult(statistic=0.0036700000000000066, pvalue=0.13493110318762094), Ks_2sampResult(statistic=0.0040000000000000036, pvalue=0.08132057739505602), Ks_2sampResult(statistic=0.004209999999999936, pvalue=0.05759063341076141), Ks_2sampResult(statistic=0.0029950000000000254, pvalue=0.33061085438663557), Ks_2sampResult(statistic=0.003605000000000025, pvalue=0.14831084006640183), Ks_2sampResult(statistic=0.003314999999999957, pvalue=0.22141106958830806), Ks_2sampResult(statistic=0.005340000000000011, pvalue=0.006642183078114614), Ks_2sampResult(statistic=0.002650000000000041, pvalue=0.4832284690563299), Ks_2sampResult(statistic=0.0041100000000000025, pvalue=0.06802471839302089), Ks_2sampResult(statistic=0.0021999999999999797, pvalue=0.7179401023155594), Ks_2sampResult(statistic=0.0032050000000000134, pvalue=0.2554012184106433), Ks_2sampResult(statistic=0.003060000000000007, pvalue=0.3058622115871852), Ks_2sampResult(statistic=0.002965000000000051, pvalue=0.34247814871586635), Ks_2sampResult(statistic=0.0026450000000000085, pvalue=0.485679672399549), Ks_2sampResult(statistic=0.003009999999999985, pvalue=0.324782401957237), Ks_2sampResult(statistic=0.003395000000000037, pvalue=0.19893041450036214), Ks_2sampResult(statistic=0.0025500000000000522, pvalue=0.5333008141715855), Ks_2sampResult(statistic=0.0027349999999999874, pvalue=0.44250794276871896), Ks_2sampResult(statistic=0.0043799999999999395, pvalue=0.042995331499732004), Ks_2sampResult(statistic=0.0027750000000000274, pvalue=0.4240055037925322), Ks_2sampResult(statistic=0.0063350000000000906, pvalue=0.0006494346884144423), Ks_2sampResult(statistic=0.0033199999999999896, pvalue=0.21995167662790643), Ks_2sampResult(statistic=0.00465500000000002, pvalue=0.026148607427389947), Ks_2sampResult(statistic=0.0034250000000000114, pvalue=0.19097034200405244), Ks_2sampResult(statistic=0.0021150000000000058, pvalue=0.7619019925243452), Ks_2sampResult(statistic=0.003950000000000009, pvalue=0.0880532271270278), Ks_2sampResult(statistic=0.004904999999999993, pvalue=0.016206845930939916), Ks_2sampResult(statistic=0.0024150000000000005, pvalue=0.6036892503797188), Ks_2sampResult(statistic=0.0017900000000000693, pvalue=0.9055624894631386), Ks_2sampResult(statistic=0.004085000000000005, pvalue=0.0708717699618065), Ks_2sampResult(statistic=0.003689999999999971, pvalue=0.1310171063142887), Ks_2sampResult(statistic=0.004190000000000027, pvalue=0.059559927169226166), Ks_2sampResult(statistic=0.002534999999999954, pvalue=0.5409852350662349), Ks_2sampResult(statistic=0.004194999999999949, pvalue=0.059062266877498285), Ks_2sampResult(statistic=0.0021499999999999853, pvalue=0.7439775887752542), Ks_2sampResult(statistic=0.003255000000000008, pvalue=0.2395007786549466), Ks_2sampResult(statistic=0.0027599999999999847, pvalue=0.43089219399319756), Ks_2sampResult(statistic=0.0038000000000000256, pvalue=0.1111112862930225), Ks_2sampResult(statistic=0.003314999999999957, pvalue=0.22141106958830806), Ks_2sampResult(statistic=0.0022899999999999865, pvalue=0.6702634398415218), Ks_2sampResult(statistic=0.005369999999999986, pvalue=0.006228476573226538), Ks_2sampResult(statistic=0.0032049999999999856, pvalue=0.25540121841065216), Ks_2sampResult(statistic=0.0029599999999999627, pvalue=0.34448323335939157), Ks_2sampResult(statistic=0.0020599999999999993, pvalue=0.7894109317033325), Ks_2sampResult(statistic=0.005720000000000058, pvalue=0.0028640617476781145), Ks_2sampResult(statistic=0.003715000000000024, pvalue=0.12625508168396715), Ks_2sampResult(statistic=0.0033049999999999746, pvalue=0.22435189487464743), Ks_2sampResult(statistic=0.006014999999999993, pvalue=0.0014323962194216122), Ks_2sampResult(statistic=0.00192500000000001, pvalue=0.8521869834732992), Ks_2sampResult(statistic=0.003794999999999993, pvalue=0.11195859358101791), Ks_2sampResult(statistic=0.004959999999999992, pvalue=0.014539023026325032), Ks_2sampResult(statistic=0.004110000000000058, pvalue=0.0680247183930147), Ks_2sampResult(statistic=0.0021400000000000308, pvalue=0.7491275314148437), Ks_2sampResult(statistic=0.003354999999999997, pvalue=0.20994011125731873), Ks_2sampResult(statistic=0.0033500000000000196, pvalue=0.2113485743816678), Ks_2sampResult(statistic=0.0024600000000000177, pvalue=0.5799557399813297), Ks_2sampResult(statistic=0.0047399999999999665, pvalue=0.022286033849140886), Ks_2sampResult(statistic=0.003275000000000028, pvalue=0.2333517997621756), Ks_2sampResult(statistic=0.0028050000000000574, pvalue=0.4104225793363979), Ks_2sampResult(statistic=0.0026700000000000057, pvalue=0.47348356941902175), Ks_2sampResult(statistic=0.004174999999999984, pvalue=0.061074536171389436), Ks_2sampResult(statistic=0.004315000000000013, pvalue=0.04814458053484534), Ks_2sampResult(statistic=0.003310000000000035, pvalue=0.2228778037312436), Ks_2sampResult(statistic=0.002589999999999981, pvalue=0.5130182023213187), Ks_2sampResult(statistic=0.0040699999999999625, pvalue=0.0726281378404669), Ks_2sampResult(statistic=0.0025550000000000017, pvalue=0.5307485013014817), Ks_2sampResult(statistic=0.0036249999999999893, pvalue=0.1440848399959419), Ks_2sampResult(statistic=0.0023499999999999632, pvalue=0.6382559447201271), Ks_2sampResult(statistic=0.005114999999999981, pvalue=0.010636311296041352), Ks_2sampResult(statistic=0.003754999999999953, pvalue=0.11893060626917283), Ks_2sampResult(statistic=0.0037800000000000056, pvalue=0.11453254382763897), Ks_2sampResult(statistic=0.002794999999999992, pvalue=0.4149217127203556), Ks_2sampResult(statistic=0.002574999999999994, pvalue=0.5205870603643127), Ks_2sampResult(statistic=0.0037850000000000383, pvalue=0.11366919928509205), Ks_2sampResult(statistic=0.0021300000000000208, pvalue=0.7542552005780286), Ks_2sampResult(statistic=0.005080000000000029, pvalue=0.011423733014314352), Ks_2sampResult(statistic=0.005610000000000004, pvalue=0.0036755050987324553), Ks_2sampResult(statistic=0.0029050000000000464, pvalue=0.36704864529202863), Ks_2sampResult(statistic=0.003950000000000009, pvalue=0.0880532271270278), Ks_2sampResult(statistic=0.004269999999999996, pvalue=0.05201482411861199), Ks_2sampResult(statistic=0.0023850000000000815, pvalue=0.619612947432728), Ks_2sampResult(statistic=0.0049899999999999944, pvalue=0.013695822942657601), Ks_2sampResult(statistic=0.006685000000000052, pvalue=0.0002608664089865696), Ks_2sampResult(statistic=0.0034150000000000014, pvalue=0.1935956925285524), Ks_2sampResult(statistic=0.008979999999999988, pvalue=1.9559669245186968e-07), Ks_2sampResult(statistic=0.0062349999999999905, pvalue=0.0008352187469849403), Ks_2sampResult(statistic=0.003060000000000007, pvalue=0.3058622115871852), Ks_2sampResult(statistic=0.002585000000000004, pvalue=0.5155360408572396), Ks_2sampResult(statistic=0.003469999999999973, pvalue=0.17949805682966205), Ks_2sampResult(statistic=0.005539999999999989, pvalue=0.004296966888082336), Ks_2sampResult(statistic=0.003895000000000093, pvalue=0.09599315952653943), Ks_2sampResult(statistic=0.003945000000000032, pvalue=0.08875151051441499), Ks_2sampResult(statistic=0.002495000000000025, pvalue=0.5616645185570933), Ks_2sampResult(statistic=0.003049999999999997, pvalue=0.3095836798209077), Ks_2sampResult(statistic=0.0065349999999999575, pvalue=0.00038796315024474797), Ks_2sampResult(statistic=0.003255000000000008, pvalue=0.2395007786549466), Ks_2sampResult(statistic=0.003714999999999996, pvalue=0.12625508168397231), Ks_2sampResult(statistic=0.0031249999999999334, pvalue=0.28243441232491306), Ks_2sampResult(statistic=0.004255000000000009, pvalue=0.05336322419248646), Ks_2sampResult(statistic=0.002139999999999989, pvalue=0.749127531414865), Ks_2sampResult(statistic=0.002574999999999994, pvalue=0.5205870603643127), Ks_2sampResult(statistic=0.0027249999999999774, pvalue=0.4472016555008783), Ks_2sampResult(statistic=0.0036399999999999766, pvalue=0.14097948999385257), Ks_2sampResult(statistic=0.002929999999999988, pvalue=0.3566762176481923), Ks_2sampResult(statistic=0.0049699999999999744, pvalue=0.014252911201599742), Ks_2sampResult(statistic=0.0023050000000000015, pvalue=0.6622651232587793), Ks_2sampResult(statistic=0.0030749999999999944, pvalue=0.300338665676129), Ks_2sampResult(statistic=0.004075000000000051, pvalue=0.07203862090280884), Ks_2sampResult(statistic=0.0035600000000000076, pvalue=0.15818372602541553), Ks_2sampResult(statistic=0.005695000000000006, pvalue=0.003032414779260942), Ks_2sampResult(statistic=0.004129999999999967, pvalue=0.06581776327259932), Ks_2sampResult(statistic=0.0043400000000000105, pvalue=0.04610412073437196), Ks_2sampResult(statistic=0.0030200000000000227, pvalue=0.3209358116199334), Ks_2sampResult(statistic=0.004744999999999999, pvalue=0.022075491593225714), Ks_2sampResult(statistic=0.0032100000000000184, pvalue=0.2537769888530339), Ks_2sampResult(statistic=0.003234999999999988, pvalue=0.2457700325587866), Ks_2sampResult(statistic=0.0032649999999999624, pvalue=0.23641130882030284), Ks_2sampResult(statistic=0.004925000000000013, pvalue=0.015581493042631468), Ks_2sampResult(statistic=0.005934999999999968, pvalue=0.001734456795920336), Ks_2sampResult(statistic=0.0033050000000000024, pvalue=0.22435189487463938), Ks_2sampResult(statistic=0.0034600000000000186, pvalue=0.18199953429864782), Ks_2sampResult(statistic=0.002975000000000061, pvalue=0.33849126796423984), Ks_2sampResult(statistic=0.0026200000000000667, pvalue=0.49802277486721835), Ks_2sampResult(statistic=0.004755000000000009, pvalue=0.02165970507777057), Ks_2sampResult(statistic=0.0029700000000000004, pvalue=0.3404808243964226), Ks_2sampResult(statistic=0.003835000000000033, pvalue=0.10532723499412604), Ks_2sampResult(statistic=0.002375000000000016, pvalue=0.6249338904351294), Ks_2sampResult(statistic=0.0036650000000000293, pvalue=0.13592429002122372), Ks_2sampResult(statistic=0.003069999999999906, pvalue=0.30217202858009956), Ks_2sampResult(statistic=0.0048000000000000265, pvalue=0.019873624433676483), Ks_2sampResult(statistic=0.003285000000000038, pvalue=0.23032213897370588), Ks_2sampResult(statistic=0.005159999999999998, pvalue=0.009696144935051687), Ks_2sampResult(statistic=0.005264999999999964, pvalue=0.007788410273180095), Ks_2sampResult(statistic=0.0029649999999999954, pvalue=0.34247814871588866), Ks_2sampResult(statistic=0.0031649999999999734, pvalue=0.2686709264576618), Ks_2sampResult(statistic=0.003794999999999993, pvalue=0.11195859358101791), Ks_2sampResult(statistic=0.0025350000000000095, pvalue=0.5409852350662063), Ks_2sampResult(statistic=0.0026349999999999985, pvalue=0.4905996685491078), Ks_2sampResult(statistic=0.00301499999999999, pvalue=0.32285520008615903), Ks_2sampResult(statistic=0.0032649999999999624, pvalue=0.23641130882030284), Ks_2sampResult(statistic=0.004955000000000015, pvalue=0.014684005119921902), Ks_2sampResult(statistic=0.0037449999999999983, pvalue=0.12072822047120788), Ks_2sampResult(statistic=0.0034049999999999914, pvalue=0.1962489994691916), Ks_2sampResult(statistic=0.0035250000000000004, pvalue=0.1662196888671422), Ks_2sampResult(statistic=0.0036399999999999766, pvalue=0.14097948999385257), Ks_2sampResult(statistic=0.0030249999999999444, pvalue=0.31902423922214307), Ks_2sampResult(statistic=0.003615000000000035, pvalue=0.1461855459973792), Ks_2sampResult(statistic=0.0036249999999999893, pvalue=0.1440848399959419), Ks_2sampResult(statistic=0.0021100000000000008, pvalue=0.7644383209429103), Ks_2sampResult(statistic=0.005209999999999992, pvalue=0.008740343244271555), Ks_2sampResult(statistic=0.0025650000000000117, pvalue=0.525658071568542), Ks_2sampResult(statistic=0.003170000000000006, pvalue=0.2669852999003843), Ks_2sampResult(statistic=0.0032050000000000134, pvalue=0.2554012184106433), Ks_2sampResult(statistic=0.004315000000000013, pvalue=0.04814458053484534), Ks_2sampResult(statistic=0.005389999999999895, pvalue=0.00596589454411636), Ks_2sampResult(statistic=0.0069550000000000445, pvalue=0.00012482187193591613), Ks_2sampResult(statistic=0.004180000000000017, pvalue=0.06056604167574671), Ks_2sampResult(statistic=0.0025600000000000067, pvalue=0.5282008956302752), Ks_2sampResult(statistic=0.002789999999999959, pvalue=0.4171820151929494), Ks_2sampResult(statistic=0.0022649999999999615, pvalue=0.6835733230656722), Ks_2sampResult(statistic=0.0029649999999999954, pvalue=0.34247814871588866), Ks_2sampResult(statistic=0.0037550000000000083, pvalue=0.11893060626916296), Ks_2sampResult(statistic=0.00387000000000004, pvalue=0.09979497342286872), Ks_2sampResult(statistic=0.006359999999999921, pvalue=0.0006094634325899431), Ks_2sampResult(statistic=0.003695000000000004, pvalue=0.13005318034617921), Ks_2sampResult(statistic=0.003569999999999962, pvalue=0.15594557998339992), Ks_2sampResult(statistic=0.003290000000000015, pvalue=0.22881846556648458), Ks_2sampResult(statistic=0.0034000000000000696, pvalue=0.19758618407746115), Ks_2sampResult(statistic=0.004964999999999997, pvalue=0.014395328340839219), Ks_2sampResult(statistic=0.0023600000000000287, pvalue=0.6329243460361065), Ks_2sampResult(statistic=0.003430000000000044, pvalue=0.18966810242808055), Ks_2sampResult(statistic=0.00381999999999999, pvalue=0.10777482304836268), Ks_2sampResult(statistic=0.003835000000000033, pvalue=0.10532723499412604), Ks_2sampResult(statistic=0.003300000000000025, pvalue=0.2258333586430296), Ks_2sampResult(statistic=0.004740000000000022, pvalue=0.022286033849138548), Ks_2sampResult(statistic=0.003940000000000055, pvalue=0.08945443207453137), Ks_2sampResult(statistic=0.004485000000000017, pvalue=0.03568709248347912), Ks_2sampResult(statistic=0.0022600000000000398, pvalue=0.6862309348331798), Ks_2sampResult(statistic=0.0024500000000000632, pvalue=0.5852108979867904), Ks_2sampResult(statistic=0.0036599999999999966, pvalue=0.1369233975611029), Ks_2sampResult(statistic=0.004945000000000088, pvalue=0.014977871276803275), Ks_2sampResult(statistic=0.003145000000000009, pvalue=0.2754906839796293), Ks_2sampResult(statistic=0.00381999999999999, pvalue=0.10777482304836268), Ks_2sampResult(statistic=0.006324999999999914, pvalue=0.0006661011595608899), Ks_2sampResult(statistic=0.00544, pvalue=0.005353103944922434), Ks_2sampResult(statistic=0.005059999999999953, pvalue=0.011896971698073237), Ks_2sampResult(statistic=0.003410000000000024, pvalue=0.19491884191740363), Ks_2sampResult(statistic=0.003630000000000022, pvalue=0.14304365133962943), Ks_2sampResult(statistic=0.0021699999999999497, pvalue=0.7336162148407397), Ks_2sampResult(statistic=0.004450000000000065, pvalue=0.03799218610336855), Ks_2sampResult(statistic=0.0031649999999999734, pvalue=0.2686709264576618), Ks_2sampResult(statistic=0.004650000000000043, pvalue=0.026393241044724975), Ks_2sampResult(statistic=0.0023900000000000032, pvalue=0.6169546365251185), Ks_2sampResult(statistic=0.004190000000000027, pvalue=0.059559927169226166)]\n"
     ]
    }
   ],
   "source": [
    "var_list = list(train.columns[2:])\n",
    "\n",
    "w = list()\n",
    "for i in var_list:\n",
    "    a = ks_2samp(train[var_list][i].values,test[var_list][i].values)\n",
    "    w.append(a)\n",
    "print(w)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio variables which meet K-S test under 5% : 0.77\n",
      "--------------------------------------------------------------------------------\n",
      "Specific variables which meet K-S test under 5%: Index(['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6', 'var_7', 'var_8',\n",
      "       'var_9', 'var_10',\n",
      "       ...\n",
      "       'var_184', 'var_185', 'var_187', 'var_188', 'var_192', 'var_193',\n",
      "       'var_194', 'var_196', 'var_198', 'var_199'],\n",
      "      dtype='object', length=154)\n",
      "--------------------------------------------------------------------------------\n",
      "Ratio variables which does not meet K-S test under 5% : 0.23\n",
      "--------------------------------------------------------------------------------\n",
      "Specific variables which does not meet K-S test under 5%: {} Index(['var_0', 'var_12', 'var_24', 'var_26', 'var_28', 'var_32', 'var_46',\n",
      "       'var_50', 'var_53', 'var_56', 'var_62', 'var_67', 'var_74', 'var_81',\n",
      "       'var_82', 'var_87', 'var_88', 'var_90', 'var_91', 'var_95', 'var_100',\n",
      "       'var_110', 'var_115', 'var_117', 'var_119', 'var_123', 'var_124',\n",
      "       'var_129', 'var_135', 'var_137', 'var_138', 'var_146', 'var_155',\n",
      "       'var_159', 'var_160', 'var_161', 'var_169', 'var_174', 'var_180',\n",
      "       'var_182', 'var_186', 'var_189', 'var_190', 'var_191', 'var_195',\n",
      "       'var_197'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "k = list()\n",
    "for i in range(len(var_list)):\n",
    "    b = w[i][1]>0.05\n",
    "    k.append(b)\n",
    "print(\"Ratio variables which meet K-S test under 5% : {}\".format(sum(k)/len(var_list)))\n",
    "print('--'*40)\n",
    "\n",
    "a = train[var_list].loc[:,k].columns\n",
    "print(\"Specific variables which meet K-S test under 5%: {}\".format(a))\n",
    "print('--'*40)\n",
    "\n",
    "a2 = train[var_list].loc[:,train[var_list].columns.isin(a) == False].columns\n",
    "print(\"Ratio variables which does not meet K-S test under 5% : {}\".format(len(a2)/len(var_list)))\n",
    "print('--'*40)\n",
    "print(\"Specific variables which does not meet K-S test under 5%: {}\",format(a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 에서 Target 에 따른 변수 별 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for var in var_list:\n",
    "    sns.distplot(train[train['target']==0][var])\n",
    "    sns.distplot(train[train['target']==1][var])\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- Deal with Nan and null value\n",
    "- Deal with outlier value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_136</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_126</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_127</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_128</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_129</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_130</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_131</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_132</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_133</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_134</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_135</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_137</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_149</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_138</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_139</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_140</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_141</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_142</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_143</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_144</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_145</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_146</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_147</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_125</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_124</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_123</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_122</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_101</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_102</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_93</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_94</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_95</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_96</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_75</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_73</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_50</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_72</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_51</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_52</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_53</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_54</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_55</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_56</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_57</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_58</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_59</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_60</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_61</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_62</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_63</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_64</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_65</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_66</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_67</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_68</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_69</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_70</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_71</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_199</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "ID_code  0\n",
       "var_136  0\n",
       "var_126  0\n",
       "var_127  0\n",
       "var_128  0\n",
       "var_129  0\n",
       "var_130  0\n",
       "var_131  0\n",
       "var_132  0\n",
       "var_133  0\n",
       "var_134  0\n",
       "var_135  0\n",
       "var_137  0\n",
       "var_149  0\n",
       "var_138  0\n",
       "var_139  0\n",
       "var_140  0\n",
       "var_141  0\n",
       "var_142  0\n",
       "var_143  0\n",
       "var_144  0\n",
       "var_145  0\n",
       "var_146  0\n",
       "var_147  0\n",
       "var_125  0\n",
       "var_124  0\n",
       "var_123  0\n",
       "var_122  0\n",
       "var_101  0\n",
       "var_102  0\n",
       "...     ..\n",
       "var_93   0\n",
       "var_94   0\n",
       "var_95   0\n",
       "var_96   0\n",
       "var_75   0\n",
       "var_73   0\n",
       "var_50   0\n",
       "var_72   0\n",
       "var_51   0\n",
       "var_52   0\n",
       "var_53   0\n",
       "var_54   0\n",
       "var_55   0\n",
       "var_56   0\n",
       "var_57   0\n",
       "var_58   0\n",
       "var_59   0\n",
       "var_60   0\n",
       "var_61   0\n",
       "var_62   0\n",
       "var_63   0\n",
       "var_64   0\n",
       "var_65   0\n",
       "var_66   0\n",
       "var_67   0\n",
       "var_68   0\n",
       "var_69   0\n",
       "var_70   0\n",
       "var_71   0\n",
       "var_199  0\n",
       "\n",
       "[202 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train Data does not have Null value\n",
    "train.isnull().sum().to_frame().sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_137</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_127</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_128</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_129</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_130</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_131</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_132</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_133</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_134</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_135</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_136</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_138</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_100</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_139</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_140</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_141</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_142</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_143</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_144</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_145</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_146</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_147</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_148</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_126</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_125</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_124</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_123</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_102</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_103</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_94</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_95</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_96</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_97</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_76</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_74</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_51</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_73</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_52</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_53</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_54</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_55</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_56</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_57</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_58</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_59</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_60</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_61</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_62</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_63</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_64</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_65</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_66</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_67</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_68</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_69</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_70</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_71</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_72</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_199</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "ID_code  0\n",
       "var_137  0\n",
       "var_127  0\n",
       "var_128  0\n",
       "var_129  0\n",
       "var_130  0\n",
       "var_131  0\n",
       "var_132  0\n",
       "var_133  0\n",
       "var_134  0\n",
       "var_135  0\n",
       "var_136  0\n",
       "var_138  0\n",
       "var_100  0\n",
       "var_139  0\n",
       "var_140  0\n",
       "var_141  0\n",
       "var_142  0\n",
       "var_143  0\n",
       "var_144  0\n",
       "var_145  0\n",
       "var_146  0\n",
       "var_147  0\n",
       "var_148  0\n",
       "var_126  0\n",
       "var_125  0\n",
       "var_124  0\n",
       "var_123  0\n",
       "var_102  0\n",
       "var_103  0\n",
       "...     ..\n",
       "var_94   0\n",
       "var_95   0\n",
       "var_96   0\n",
       "var_97   0\n",
       "var_76   0\n",
       "var_74   0\n",
       "var_51   0\n",
       "var_73   0\n",
       "var_52   0\n",
       "var_53   0\n",
       "var_54   0\n",
       "var_55   0\n",
       "var_56   0\n",
       "var_57   0\n",
       "var_58   0\n",
       "var_59   0\n",
       "var_60   0\n",
       "var_61   0\n",
       "var_62   0\n",
       "var_63   0\n",
       "var_64   0\n",
       "var_65   0\n",
       "var_66   0\n",
       "var_67   0\n",
       "var_68   0\n",
       "var_69   0\n",
       "var_70   0\n",
       "var_71   0\n",
       "var_72   0\n",
       "var_199  0\n",
       "\n",
       "[201 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test Data also does not have Null value\n",
    "test.isnull().sum().to_frame().sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is no linear correlation in train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0005437 ,  0.00657283,  0.00380076, ...,  0.00060689,\n",
       "        0.00499055, -0.00473056])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_corr = train.iloc[:,2:].corr()\n",
    "tr_corr = tr_corr.values.flatten()\n",
    "tr_corr = tr_corr[tr_corr != 1]\n",
    "tr_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio which is of correlation of X variables in train set under 0.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio which is of correlation of X variables in train set under 0.1 : {}\".format(sum(abs(tr_corr) < 0.01) / len(tr_corr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00423351,  0.00262497,  0.00084712, ...,  0.00205493,\n",
       "        0.00335979, -0.00083358])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_corr = test.iloc[:,1:].corr()\n",
    "te_corr = te_corr.values.flatten()\n",
    "te_corr = te_corr[te_corr != 1]\n",
    "te_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio which is of correlation of X variables in test set under 0.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio which is of correlation of X variables in test set under 0.1 : {}\".format(sum(abs(te_corr) < 0.01) / len(te_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Select input variables\n",
    "- (1) Select important input variables\n",
    "- (2) PCA(Principal Component Analysis)\n",
    "- (3) Generate the index highly related to Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Select input Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)-1 Processing Permutation Importance\n",
    "\n",
    "criteria : baseline model<Wooil's Neural Network>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_col = list(train.columns)[2:]\n",
    "output_col = list(train.columns)[1]\n",
    "\n",
    "X_dataset = train[input_col]\n",
    "y_dataset = train[output_col]\n",
    "\n",
    "X_test_dataset = test[input_col]\n",
    "\n",
    "# Split data into train and test data \n",
    "# Ratio = train : test = 8 : 2 \n",
    "\n",
    "cutline = int(len(train)*0.8)\n",
    "\n",
    "X_dataset_80 = X_dataset[:cutline]\n",
    "X_dataset_20 = X_dataset[cutline:]\n",
    "\n",
    "y_dataset_80 = y_dataset[:cutline]\n",
    "y_dataset_20 = y_dataset[cutline:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_dataset_80)\n",
    "\n",
    "X_train = scaler.transform(X_dataset_80)\n",
    "X_validation = scaler.transform(X_dataset_20)\n",
    "X_test = scaler.transform(X_test_dataset)\n",
    "\n",
    "y_train = y_dataset_80\n",
    "y_validation = y_dataset_20\n",
    "\n",
    "train_org = train[:cutline]\n",
    "validation_org = train[cutline:]\n",
    "\n",
    "print(\"Train :\", len(X_train))\n",
    "print(\"Validation :\", len(X_validation))\n",
    "print('Test :', len(X_test))\n",
    "\n",
    "# SMOTE Technique for dealing with imbalance problem#\n",
    "sm = SMOTE(ratio = 1, kind = 'regular', random_state = 12)\n",
    "# kind = ['regular', 'borderline1', 'borderline2', 'svm']\n",
    "\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of X_train: {}'.format(X_train.shape))\n",
    "print('After OverSampling, the shape of y_train: {} \\n'.format(y_train.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train==0)))\n",
    "\n",
    "\n",
    "def base_model():\n",
    "    # 모델 \n",
    "    model = Sequential()\n",
    "\n",
    "    # Hidden Layer1\n",
    "    model.add(Dense(400, input_dim = input_size ,init = 'glorot_normal', use_bias = True, bias_initializer = 'zeros'))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    # Hidden Layer2\n",
    "    model.add(Dense(400, init = 'glorot_normal'))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(output_dim = 1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # 모델 학습과정 설정하기\n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy']) #rmsprop adam\n",
    "    return model\n",
    "\n",
    "clf = KerasClassifier(build_fn = base_model, epochs = epochs, batch_size = batch_size)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "per_importance = PermutationImportance(clf,random_state = 12).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eli5.show_weights(per_importance,top = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)-2.Recursive Feature Elimination</bs>\n",
    "\n",
    "RFE(Recursive Feature Elimination) method works by removing attributes recursively and finds which attributes are important to predict the output attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)-3.Feature importance using Ensembles of decision trees</bs>\n",
    "\n",
    "Ensembles of decision trees can be used to select important attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit Extra Tree model to the train data\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators = 100,\n",
    "                             )\n",
    "\n",
    "model.fit(train.iloc[:,2:],\n",
    "          train.iloc[:,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) PCA(Principal Components Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_train_x = train.iloc[:,2:].values\n",
    "pca_test_x = test.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features \n",
    "pca_train_x = StandardScaler().fit_transform(pca_train_x)\n",
    "pca_test_x = StandardScaler().fit_transform(pca_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 150,\n",
    "          svd_solver = 'auto',\n",
    "          random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_compo_tr = pca.fit_transform(pca_train_x)\n",
    "principal_compo_te = pca.fit_transform(pca_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_140</th>\n",
       "      <th>var_141</th>\n",
       "      <th>var_142</th>\n",
       "      <th>var_143</th>\n",
       "      <th>var_144</th>\n",
       "      <th>var_145</th>\n",
       "      <th>var_146</th>\n",
       "      <th>var_147</th>\n",
       "      <th>var_148</th>\n",
       "      <th>var_149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.565058</td>\n",
       "      <td>-1.286815</td>\n",
       "      <td>-0.052384</td>\n",
       "      <td>0.907197</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>-0.883561</td>\n",
       "      <td>0.166516</td>\n",
       "      <td>-0.391172</td>\n",
       "      <td>-0.053866</td>\n",
       "      <td>0.263147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790655</td>\n",
       "      <td>1.363773</td>\n",
       "      <td>-0.223893</td>\n",
       "      <td>0.471139</td>\n",
       "      <td>-0.537195</td>\n",
       "      <td>-0.245197</td>\n",
       "      <td>0.936733</td>\n",
       "      <td>-1.332775</td>\n",
       "      <td>1.019966</td>\n",
       "      <td>0.178121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.495162</td>\n",
       "      <td>0.186593</td>\n",
       "      <td>0.224538</td>\n",
       "      <td>-0.009524</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>-0.107675</td>\n",
       "      <td>0.920689</td>\n",
       "      <td>0.390032</td>\n",
       "      <td>-1.500828</td>\n",
       "      <td>1.429078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308173</td>\n",
       "      <td>-0.089517</td>\n",
       "      <td>-0.336982</td>\n",
       "      <td>0.916061</td>\n",
       "      <td>0.827481</td>\n",
       "      <td>-0.676124</td>\n",
       "      <td>-1.085506</td>\n",
       "      <td>-0.526134</td>\n",
       "      <td>0.773371</td>\n",
       "      <td>1.510587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.126464</td>\n",
       "      <td>-0.088453</td>\n",
       "      <td>-0.606849</td>\n",
       "      <td>-0.799541</td>\n",
       "      <td>0.816255</td>\n",
       "      <td>-0.597386</td>\n",
       "      <td>-0.251139</td>\n",
       "      <td>0.145980</td>\n",
       "      <td>-0.144911</td>\n",
       "      <td>0.751865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>-1.032999</td>\n",
       "      <td>-0.219104</td>\n",
       "      <td>-0.098147</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>-0.878681</td>\n",
       "      <td>-0.266594</td>\n",
       "      <td>-0.324444</td>\n",
       "      <td>-0.189480</td>\n",
       "      <td>-0.575689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.166322</td>\n",
       "      <td>-0.221439</td>\n",
       "      <td>1.018527</td>\n",
       "      <td>-1.048291</td>\n",
       "      <td>0.506151</td>\n",
       "      <td>-0.881075</td>\n",
       "      <td>-0.117602</td>\n",
       "      <td>-0.027276</td>\n",
       "      <td>1.245131</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>-1.019573</td>\n",
       "      <td>0.625304</td>\n",
       "      <td>-1.548323</td>\n",
       "      <td>-0.539651</td>\n",
       "      <td>-1.120833</td>\n",
       "      <td>2.100956</td>\n",
       "      <td>-1.086960</td>\n",
       "      <td>-1.153350</td>\n",
       "      <td>2.035715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.447454</td>\n",
       "      <td>0.728456</td>\n",
       "      <td>0.428742</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>-0.614091</td>\n",
       "      <td>1.211479</td>\n",
       "      <td>-0.734313</td>\n",
       "      <td>0.578402</td>\n",
       "      <td>-1.542590</td>\n",
       "      <td>-1.240075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761264</td>\n",
       "      <td>-0.842436</td>\n",
       "      <td>-0.548476</td>\n",
       "      <td>-0.744569</td>\n",
       "      <td>-0.111326</td>\n",
       "      <td>0.483443</td>\n",
       "      <td>-1.514879</td>\n",
       "      <td>-1.092605</td>\n",
       "      <td>-1.206925</td>\n",
       "      <td>0.724841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0 -0.565058 -1.286815 -0.052384  0.907197 -0.309077 -0.883561  0.166516   \n",
       "1  2.495162  0.186593  0.224538 -0.009524  0.762327 -0.107675  0.920689   \n",
       "2 -0.126464 -0.088453 -0.606849 -0.799541  0.816255 -0.597386 -0.251139   \n",
       "3  1.166322 -0.221439  1.018527 -1.048291  0.506151 -0.881075 -0.117602   \n",
       "4  0.447454  0.728456  0.428742  0.664404 -0.614091  1.211479 -0.734313   \n",
       "\n",
       "      var_7     var_8     var_9    ...      var_140   var_141   var_142  \\\n",
       "0 -0.391172 -0.053866  0.263147    ...     0.790655  1.363773 -0.223893   \n",
       "1  0.390032 -1.500828  1.429078    ...     0.308173 -0.089517 -0.336982   \n",
       "2  0.145980 -0.144911  0.751865    ...     0.198300 -1.032999 -0.219104   \n",
       "3 -0.027276  1.245131  0.053467    ...     0.126221 -1.019573  0.625304   \n",
       "4  0.578402 -1.542590 -1.240075    ...    -0.761264 -0.842436 -0.548476   \n",
       "\n",
       "    var_143   var_144   var_145   var_146   var_147   var_148   var_149  \n",
       "0  0.471139 -0.537195 -0.245197  0.936733 -1.332775  1.019966  0.178121  \n",
       "1  0.916061  0.827481 -0.676124 -1.085506 -0.526134  0.773371  1.510587  \n",
       "2 -0.098147  0.024887 -0.878681 -0.266594 -0.324444 -0.189480 -0.575689  \n",
       "3 -1.548323 -0.539651 -1.120833  2.100956 -1.086960 -1.153350  2.035715  \n",
       "4 -0.744569 -0.111326  0.483443 -1.514879 -1.092605 -1.206925  0.724841  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(data = principal_compo_tr,\n",
    "                        columns = train.iloc[:,2:152].columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_140</th>\n",
       "      <th>var_141</th>\n",
       "      <th>var_142</th>\n",
       "      <th>var_143</th>\n",
       "      <th>var_144</th>\n",
       "      <th>var_145</th>\n",
       "      <th>var_146</th>\n",
       "      <th>var_147</th>\n",
       "      <th>var_148</th>\n",
       "      <th>var_149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185196</td>\n",
       "      <td>0.544392</td>\n",
       "      <td>0.761958</td>\n",
       "      <td>1.399017</td>\n",
       "      <td>0.876586</td>\n",
       "      <td>0.321723</td>\n",
       "      <td>-0.820455</td>\n",
       "      <td>0.178102</td>\n",
       "      <td>-0.586441</td>\n",
       "      <td>0.978557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090609</td>\n",
       "      <td>-0.669799</td>\n",
       "      <td>1.059813</td>\n",
       "      <td>1.686759</td>\n",
       "      <td>-0.854786</td>\n",
       "      <td>1.588536</td>\n",
       "      <td>-0.632784</td>\n",
       "      <td>0.440865</td>\n",
       "      <td>-1.450089</td>\n",
       "      <td>-0.009517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.110500</td>\n",
       "      <td>-0.687579</td>\n",
       "      <td>0.789056</td>\n",
       "      <td>0.695684</td>\n",
       "      <td>-0.096331</td>\n",
       "      <td>1.038258</td>\n",
       "      <td>0.105293</td>\n",
       "      <td>-0.093627</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-0.972977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896177</td>\n",
       "      <td>1.220073</td>\n",
       "      <td>1.091706</td>\n",
       "      <td>0.130185</td>\n",
       "      <td>0.489506</td>\n",
       "      <td>-0.195060</td>\n",
       "      <td>0.724590</td>\n",
       "      <td>0.670840</td>\n",
       "      <td>-0.545606</td>\n",
       "      <td>-0.901790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.468404</td>\n",
       "      <td>1.576627</td>\n",
       "      <td>0.799260</td>\n",
       "      <td>1.726625</td>\n",
       "      <td>0.618498</td>\n",
       "      <td>0.042487</td>\n",
       "      <td>1.063649</td>\n",
       "      <td>-0.629277</td>\n",
       "      <td>0.248393</td>\n",
       "      <td>3.540199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405643</td>\n",
       "      <td>-0.659104</td>\n",
       "      <td>-0.629750</td>\n",
       "      <td>-1.238191</td>\n",
       "      <td>-0.172306</td>\n",
       "      <td>0.878381</td>\n",
       "      <td>-1.120614</td>\n",
       "      <td>0.818652</td>\n",
       "      <td>-0.481389</td>\n",
       "      <td>0.777516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.468055</td>\n",
       "      <td>0.387864</td>\n",
       "      <td>0.661236</td>\n",
       "      <td>0.917826</td>\n",
       "      <td>-0.662956</td>\n",
       "      <td>0.447297</td>\n",
       "      <td>2.244682</td>\n",
       "      <td>0.877475</td>\n",
       "      <td>0.842288</td>\n",
       "      <td>-1.589454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.973762</td>\n",
       "      <td>-1.355145</td>\n",
       "      <td>0.617007</td>\n",
       "      <td>-0.575144</td>\n",
       "      <td>0.876817</td>\n",
       "      <td>1.273570</td>\n",
       "      <td>-1.247758</td>\n",
       "      <td>1.454953</td>\n",
       "      <td>-0.899561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348757</td>\n",
       "      <td>-1.195222</td>\n",
       "      <td>-0.723480</td>\n",
       "      <td>-0.036989</td>\n",
       "      <td>-0.527582</td>\n",
       "      <td>1.158022</td>\n",
       "      <td>0.605976</td>\n",
       "      <td>-1.058362</td>\n",
       "      <td>-0.719639</td>\n",
       "      <td>-0.085354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339941</td>\n",
       "      <td>-0.691205</td>\n",
       "      <td>-1.017586</td>\n",
       "      <td>1.897238</td>\n",
       "      <td>0.731851</td>\n",
       "      <td>0.843774</td>\n",
       "      <td>-0.332323</td>\n",
       "      <td>-0.919826</td>\n",
       "      <td>1.409617</td>\n",
       "      <td>-0.094861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0  0.185196  0.544392  0.761958  1.399017  0.876586  0.321723 -0.820455   \n",
       "1  1.110500 -0.687579  0.789056  0.695684 -0.096331  1.038258  0.105293   \n",
       "2  0.468404  1.576627  0.799260  1.726625  0.618498  0.042487  1.063649   \n",
       "3  0.468055  0.387864  0.661236  0.917826 -0.662956  0.447297  2.244682   \n",
       "4  0.348757 -1.195222 -0.723480 -0.036989 -0.527582  1.158022  0.605976   \n",
       "\n",
       "      var_7     var_8     var_9    ...      var_140   var_141   var_142  \\\n",
       "0  0.178102 -0.586441  0.978557    ...     1.090609 -0.669799  1.059813   \n",
       "1 -0.093627 -0.001096 -0.972977    ...     0.896177  1.220073  1.091706   \n",
       "2 -0.629277  0.248393  3.540199    ...     0.405643 -0.659104 -0.629750   \n",
       "3  0.877475  0.842288 -1.589454    ...     0.026691  0.973762 -1.355145   \n",
       "4 -1.058362 -0.719639 -0.085354    ...     1.339941 -0.691205 -1.017586   \n",
       "\n",
       "    var_143   var_144   var_145   var_146   var_147   var_148   var_149  \n",
       "0  1.686759 -0.854786  1.588536 -0.632784  0.440865 -1.450089 -0.009517  \n",
       "1  0.130185  0.489506 -0.195060  0.724590  0.670840 -0.545606 -0.901790  \n",
       "2 -1.238191 -0.172306  0.878381 -1.120614  0.818652 -0.481389  0.777516  \n",
       "3  0.617007 -0.575144  0.876817  1.273570 -1.247758  1.454953 -0.899561  \n",
       "4  1.897238  0.731851  0.843774 -0.332323 -0.919826  1.409617 -0.094861  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(data = principal_compo_te,\n",
    "                       columns = test.iloc[:,1:151].columns)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_141</th>\n",
       "      <th>var_142</th>\n",
       "      <th>var_143</th>\n",
       "      <th>var_144</th>\n",
       "      <th>var_145</th>\n",
       "      <th>var_146</th>\n",
       "      <th>var_147</th>\n",
       "      <th>var_148</th>\n",
       "      <th>var_149</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.565058</td>\n",
       "      <td>-1.286815</td>\n",
       "      <td>-0.052384</td>\n",
       "      <td>0.907197</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>-0.883561</td>\n",
       "      <td>0.166516</td>\n",
       "      <td>-0.391172</td>\n",
       "      <td>-0.053866</td>\n",
       "      <td>0.263147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363773</td>\n",
       "      <td>-0.223893</td>\n",
       "      <td>0.471139</td>\n",
       "      <td>-0.537195</td>\n",
       "      <td>-0.245197</td>\n",
       "      <td>0.936733</td>\n",
       "      <td>-1.332775</td>\n",
       "      <td>1.019966</td>\n",
       "      <td>0.178121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.495162</td>\n",
       "      <td>0.186593</td>\n",
       "      <td>0.224538</td>\n",
       "      <td>-0.009524</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>-0.107675</td>\n",
       "      <td>0.920689</td>\n",
       "      <td>0.390032</td>\n",
       "      <td>-1.500828</td>\n",
       "      <td>1.429078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089517</td>\n",
       "      <td>-0.336982</td>\n",
       "      <td>0.916061</td>\n",
       "      <td>0.827481</td>\n",
       "      <td>-0.676124</td>\n",
       "      <td>-1.085506</td>\n",
       "      <td>-0.526134</td>\n",
       "      <td>0.773371</td>\n",
       "      <td>1.510587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.126464</td>\n",
       "      <td>-0.088453</td>\n",
       "      <td>-0.606849</td>\n",
       "      <td>-0.799541</td>\n",
       "      <td>0.816255</td>\n",
       "      <td>-0.597386</td>\n",
       "      <td>-0.251139</td>\n",
       "      <td>0.145980</td>\n",
       "      <td>-0.144911</td>\n",
       "      <td>0.751865</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.032999</td>\n",
       "      <td>-0.219104</td>\n",
       "      <td>-0.098147</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>-0.878681</td>\n",
       "      <td>-0.266594</td>\n",
       "      <td>-0.324444</td>\n",
       "      <td>-0.189480</td>\n",
       "      <td>-0.575689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.166322</td>\n",
       "      <td>-0.221439</td>\n",
       "      <td>1.018527</td>\n",
       "      <td>-1.048291</td>\n",
       "      <td>0.506151</td>\n",
       "      <td>-0.881075</td>\n",
       "      <td>-0.117602</td>\n",
       "      <td>-0.027276</td>\n",
       "      <td>1.245131</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.019573</td>\n",
       "      <td>0.625304</td>\n",
       "      <td>-1.548323</td>\n",
       "      <td>-0.539651</td>\n",
       "      <td>-1.120833</td>\n",
       "      <td>2.100956</td>\n",
       "      <td>-1.086960</td>\n",
       "      <td>-1.153350</td>\n",
       "      <td>2.035715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.447454</td>\n",
       "      <td>0.728456</td>\n",
       "      <td>0.428742</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>-0.614091</td>\n",
       "      <td>1.211479</td>\n",
       "      <td>-0.734313</td>\n",
       "      <td>0.578402</td>\n",
       "      <td>-1.542590</td>\n",
       "      <td>-1.240075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.842436</td>\n",
       "      <td>-0.548476</td>\n",
       "      <td>-0.744569</td>\n",
       "      <td>-0.111326</td>\n",
       "      <td>0.483443</td>\n",
       "      <td>-1.514879</td>\n",
       "      <td>-1.092605</td>\n",
       "      <td>-1.206925</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0 -0.565058 -1.286815 -0.052384  0.907197 -0.309077 -0.883561  0.166516   \n",
       "1  2.495162  0.186593  0.224538 -0.009524  0.762327 -0.107675  0.920689   \n",
       "2 -0.126464 -0.088453 -0.606849 -0.799541  0.816255 -0.597386 -0.251139   \n",
       "3  1.166322 -0.221439  1.018527 -1.048291  0.506151 -0.881075 -0.117602   \n",
       "4  0.447454  0.728456  0.428742  0.664404 -0.614091  1.211479 -0.734313   \n",
       "\n",
       "      var_7     var_8     var_9   ...     var_141   var_142   var_143  \\\n",
       "0 -0.391172 -0.053866  0.263147   ...    1.363773 -0.223893  0.471139   \n",
       "1  0.390032 -1.500828  1.429078   ...   -0.089517 -0.336982  0.916061   \n",
       "2  0.145980 -0.144911  0.751865   ...   -1.032999 -0.219104 -0.098147   \n",
       "3 -0.027276  1.245131  0.053467   ...   -1.019573  0.625304 -1.548323   \n",
       "4  0.578402 -1.542590 -1.240075   ...   -0.842436 -0.548476 -0.744569   \n",
       "\n",
       "    var_144   var_145   var_146   var_147   var_148   var_149  target  \n",
       "0 -0.537195 -0.245197  0.936733 -1.332775  1.019966  0.178121       0  \n",
       "1  0.827481 -0.676124 -1.085506 -0.526134  0.773371  1.510587       0  \n",
       "2  0.024887 -0.878681 -0.266594 -0.324444 -0.189480 -0.575689       0  \n",
       "3 -0.539651 -1.120833  2.100956 -1.086960 -1.153350  2.035715       0  \n",
       "4 -0.111326  0.483443 -1.514879 -1.092605 -1.206925  0.724841       0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'] = pca_y_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split full data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split data(training : validation = 80:20)\n",
    "ind = int(len(train) * 0.8)\n",
    "\n",
    "x_train_80 = df_train[:ind]\n",
    "x_train_20 = df_train[ind:]\n",
    "\n",
    "x_train = x_train_80.iloc[:,:-1]\n",
    "x_validation = x_train_20.iloc[:,:-1]\n",
    "\n",
    "y_train = x_train_80.iloc[:,-1:]\n",
    "y_validation = x_train_20.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution of serious imbalance problem in Y variable in train data\n",
    "\n",
    "-ex.Oversampling,Undersampling,Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16049"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((y_train == 1).values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-4bec941bbfa1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-65-4bec941bbfa1>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum((y_train==0).values)[0])\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum((y_train==1).values)[0])\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum((y_train==0).values)[0])\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum((y_validation==1).values)[0])\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum((y_validation==0).values)[0])\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", x_train.shape)\n",
    "print(\"Number transactions Y_train dataset: \", y_train.shape,'\\n')\n",
    "\n",
    "print(\"Number transactions X_test dataset: \", x_validation.shape)\n",
    "print(\"Number transactions Y_test dataset: \", y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef model_fit_h2(x_train,y_train,x_validation,y_validation,n_nodes,ke_i,bi_i,acti,optimi,n_epochs,n_batch):\\n    \\n    # n_nodes = [150,300,400,500]\\n    # Ke_i = 'lecun_uniform', ' lecun_noraml','glorot_normal','glorot_uniform','he_normal','he_uniform'\\n    # bi_i = 'Zeros', 'Ones'\\n    # acti : 'elu', 'selu', 'softplus', 'softsign','relu','tanh','sigmoid','hard_sigmoid','exponential'\\n    # optimi = 'rmsprop', 'adam' \\n    # n_epochs = 10,50,100\\n    # n_batch = 1,100,300\\n    \\n    # Define model\\n    model = Sequential()\\n    model.add(Dense(n_nodes,\\n                    kernel_initializer = ke_i,\\n                    use_bias = True,\\n                    bias_initializer = bi_i,\\n                    activation = acti,\\n                    input_dim = x_train.shape[1]))\\n    model.add(Dense(n_nodes,\\n                    kernel_initializer = ke_i,\\n                    use_bias = True,\\n                    bias_initializer = bi_i,\\n                    activation = acti))\\n    model.add(Dense(output_dim = 1,activation = 'sigmoid'))\\n    #model.add(Activation('sigmoid'))\\n    model.compile(optimizer = optimi, loss = 'binary_crossentropy', metrics = ['accuracy']) \\n    \\n    # fit model\\n    history = model.fit(x_train,y_train,epochs = n_epochs,batch_size = n_batch,verbose=0)\\n    \\n    # Evaluate model on test set\\n    _, test_acc = model.evaluate(x_validation,y_validation,verbose=0)\\n    return history,test_acc\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def model_fit_h2(x_train,y_train,x_validation,y_validation,n_nodes,ke_i,bi_i,acti,optimi,n_epochs,n_batch):\n",
    "    \n",
    "    # n_nodes = [150,300,400,500]\n",
    "    # Ke_i = 'lecun_uniform', ' lecun_noraml','glorot_normal','glorot_uniform','he_normal','he_uniform'\n",
    "    # bi_i = 'Zeros', 'Ones'\n",
    "    # acti : 'elu', 'selu', 'softplus', 'softsign','relu','tanh','sigmoid','hard_sigmoid','exponential'\n",
    "    # optimi = 'rmsprop', 'adam' \n",
    "    # n_epochs = 10,50,100\n",
    "    # n_batch = 1,100,300\n",
    "    \n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes,\n",
    "                    kernel_initializer = ke_i,\n",
    "                    use_bias = True,\n",
    "                    bias_initializer = bi_i,\n",
    "                    activation = acti,\n",
    "                    input_dim = x_train.shape[1]))\n",
    "    model.add(Dense(n_nodes,\n",
    "                    kernel_initializer = ke_i,\n",
    "                    use_bias = True,\n",
    "                    bias_initializer = bi_i,\n",
    "                    activation = acti))\n",
    "    model.add(Dense(output_dim = 1,activation = 'sigmoid'))\n",
    "    #model.add(Activation('sigmoid'))\n",
    "    model.compile(optimizer = optimi, loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit(x_train,y_train,epochs = n_epochs,batch_size = n_batch,verbose=0)\n",
    "    \n",
    "    # Evaluate model on test set\n",
    "    _, test_acc = model.evaluate(x_validation,y_validation,verbose=0)\n",
    "    return history,test_acc\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_nodes = [150,300,400,500]\\nke_i = [\\'lecun_uniform\\',\\'lecun_noraml\\',\\'glorot_normal\\',\\'glorot_uniform\\',\\'he_normal\\',\\'he_uniform\\']\\nbi_i = [\\'Zeros\\',\\'Ones\\']\\nacti = [\\'elu\\', \\'selu\\', \\'softplus\\', \\'softsign\\',\\'relu\\',\\'tanh\\',\\'sigmoid\\',\\'hard_sigmoid\\',\\'exponential\\']\\noptimi = [\\'rmsprop\\',\\'adam\\']\\nn_epochs = [10,50,100]\\nn_batch = [1,100,300]\\n\\nfor a in n_nodes:\\n    for b in ke_i:\\n        for c in bi_i:\\n            for d in acti:\\n                for e in optimi:\\n                    for f in n_epochs:\\n                        for g in n_batch:\\n                            history,result = model_fit_h2(x_train,y_train,x_validation,y_validation,a,b,c,d,e,f,g)\\n                            print(\"n_nodes:{},ke_i:{},bi_i:{},acti:{},optimi:{},n_epochs:{},n_batch:{},test accuracy:{}\".format(a,b,c,d,e,f,g,result))\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "n_nodes = [150,300,400,500]\n",
    "ke_i = ['lecun_uniform','lecun_noraml','glorot_normal','glorot_uniform','he_normal','he_uniform']\n",
    "bi_i = ['Zeros','Ones']\n",
    "acti = ['elu', 'selu', 'softplus', 'softsign','relu','tanh','sigmoid','hard_sigmoid','exponential']\n",
    "optimi = ['rmsprop','adam']\n",
    "n_epochs = [10,50,100]\n",
    "n_batch = [1,100,300]\n",
    "\n",
    "for a in n_nodes:\n",
    "    for b in ke_i:\n",
    "        for c in bi_i:\n",
    "            for d in acti:\n",
    "                for e in optimi:\n",
    "                    for f in n_epochs:\n",
    "                        for g in n_batch:\n",
    "                            history,result = model_fit_h2(x_train,y_train,x_validation,y_validation,a,b,c,d,e,f,g)\n",
    "                            print(\"n_nodes:{},ke_i:{},bi_i:{},acti:{},optimi:{},n_epochs:{},n_batch:{},test accuracy:{}\".format(a,b,c,d,e,f,g,result))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lions\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(300, input_dim=150, use_bias=True, bias_initializer=\"zeros\", kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "C:\\Users\\lions\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(300, kernel_initializer=\"glorot_normal\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\lions\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(300, kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "C:\\Users\\lions\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/20\n",
      "128000/128000 [==============================] - 7s 52us/step - loss: 0.8019 - acc: 0.4261 - val_loss: 0.5234 - val_acc: 0.7910\n",
      "Epoch 2/20\n",
      "128000/128000 [==============================] - 5s 43us/step - loss: 0.5215 - acc: 0.7922 - val_loss: 0.3820 - val_acc: 0.8923\n",
      "Epoch 3/20\n",
      "128000/128000 [==============================] - 6s 45us/step - loss: 0.3783 - acc: 0.8936 - val_loss: 0.3482 - val_acc: 0.8983\n",
      "Epoch 4/20\n",
      "128000/128000 [==============================] - 6s 44us/step - loss: 0.3427 - acc: 0.8998 - val_loss: 0.3557 - val_acc: 0.8986\n",
      "Epoch 5/20\n",
      "128000/128000 [==============================] - 6s 43us/step - loss: 0.3491 - acc: 0.9000 - val_loss: 0.3591 - val_acc: 0.8986\n",
      "Epoch 6/20\n",
      "128000/128000 [==============================] - 6s 46us/step - loss: 0.3520 - acc: 0.9000 - val_loss: 0.3479 - val_acc: 0.8987\n",
      "Epoch 7/20\n",
      "128000/128000 [==============================] - 6s 43us/step - loss: 0.3409 - acc: 0.9000 - val_loss: 0.3251 - val_acc: 0.8987\n",
      "Epoch 8/20\n",
      "128000/128000 [==============================] - 6s 43us/step - loss: 0.3187 - acc: 0.9003 - val_loss: 0.2989 - val_acc: 0.8996\n",
      "Epoch 9/20\n",
      "128000/128000 [==============================] - 6s 45us/step - loss: 0.2934 - acc: 0.9017 - val_loss: 0.2792 - val_acc: 0.9017\n",
      "Epoch 10/20\n",
      "128000/128000 [==============================] - 6s 43us/step - loss: 0.2752 - acc: 0.9033 - val_loss: 0.2728 - val_acc: 0.9004\n",
      "Epoch 11/20\n",
      "128000/128000 [==============================] - 5s 42us/step - loss: 0.2706 - acc: 0.9020 - val_loss: 0.2770 - val_acc: 0.8945\n",
      "Epoch 12/20\n",
      "128000/128000 [==============================] - 6s 45us/step - loss: 0.2765 - acc: 0.8950 - val_loss: 0.2803 - val_acc: 0.8899\n",
      "Epoch 13/20\n",
      "128000/128000 [==============================] - 5s 42us/step - loss: 0.2812 - acc: 0.8907 - val_loss: 0.2760 - val_acc: 0.8910\n",
      "Epoch 14/20\n",
      "128000/128000 [==============================] - 6s 45us/step - loss: 0.2776 - acc: 0.8917 - val_loss: 0.2674 - val_acc: 0.8959\n",
      "Epoch 15/20\n",
      "128000/128000 [==============================] - 6s 44us/step - loss: 0.2690 - acc: 0.8967 - val_loss: 0.2605 - val_acc: 0.9005\n",
      "Epoch 16/20\n",
      "128000/128000 [==============================] - 5s 43us/step - loss: 0.2614 - acc: 0.9010 - val_loss: 0.2586 - val_acc: 0.9027\n",
      "Epoch 17/20\n",
      "128000/128000 [==============================] - 6s 44us/step - loss: 0.2584 - acc: 0.9042 - val_loss: 0.2612 - val_acc: 0.9031\n",
      "Epoch 18/20\n",
      "128000/128000 [==============================] - 6s 43us/step - loss: 0.2598 - acc: 0.9050 - val_loss: 0.2655 - val_acc: 0.9036\n",
      "Epoch 19/20\n",
      "128000/128000 [==============================] - 5s 41us/step - loss: 0.2630 - acc: 0.9057 - val_loss: 0.2689 - val_acc: 0.9040\n",
      "Epoch 20/20\n",
      "128000/128000 [==============================] - 6s 44us/step - loss: 0.2656 - acc: 0.9059 - val_loss: 0.2698 - val_acc: 0.9040\n",
      "Running Time : 113.92초\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#======================================================================\n",
    "# 모델 \n",
    "\n",
    "def base_model(acti = 'tanh',init = 'glorot_normal',bias_initializer='zeros'): \n",
    "    model = Sequential()\n",
    "    # Hidden Layer1\n",
    "    model.add(Dense(300, input_dim = x_train.shape[1] ,init = 'glorot_normal', use_bias = True, bias_initializer = 'zeros'))\n",
    "    model.add(Activation(acti))\n",
    "    # Hidden Layer2\n",
    "    model.add(Dense(300, init = 'glorot_normal'))\n",
    "    model.add(Activation(acti))\n",
    "    # Hidden Layer 3\n",
    "    model.add(Dense(300, init = 'glorot_normal'))\n",
    "    model.add(Activation(acti))\n",
    "    # Output Layer\n",
    "    model.add(Dense(output_dim = 1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy']) #rmsprop adam\n",
    "    return model\n",
    "\n",
    "# Train model\n",
    "\n",
    "a = base_model(acti='elu')\n",
    "\n",
    "hist = a.fit(x_train, \n",
    "             y_train, \n",
    "             epochs = 20, \n",
    "             batch_size = int(len(x_train)*0.8),\n",
    "             shuffle = True,\n",
    "             validation_split=0.2)\n",
    "#======================================================================\n",
    "print('Running Time : %.02f초' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35476  3325]\n",
      " [  475   724]]\n",
      "Accuracy : 0.905\n",
      "Sensitivity : 0.1788\n",
      "Precision : 0.6038\n",
      "F1-Measure : 0.2759\n",
      "F2-Measure : 0.2081\n"
     ]
    }
   ],
   "source": [
    "train_org = df_train[:ind]\n",
    "validation_org = df_train[ind:]\n",
    "\n",
    "pred_val = a.predict(x_validation)\n",
    "pred = np.array(pred_val > 0.5, dtype = int)\n",
    "validation_org['pred_val'] = pred_val\n",
    "validation_org['pred'] = pred\n",
    "\n",
    "CM = confusion_matrix(validation_org['pred'], validation_org['target'])\n",
    "\n",
    "sensitivity = CM[1,1]/(CM[0,1] + CM[1,1])\n",
    "precision = CM[1,1]/(CM[1,0] + CM[1,1])\n",
    "f1_measure = 2*(sensitivity*precision) / (sensitivity+precision)\n",
    "beta = 2\n",
    "fn_measure = (1 + (beta**2))*(sensitivity*precision) / (((beta**2)*precision)+sensitivity)\n",
    "\n",
    "R_F_sum = CM[0,1] + CM[1,1]\n",
    "R_P_sum = CM[0,0] + CM[1,0]\n",
    "Accuracy = (CM[0,0] + CM[1,1])/(R_F_sum + R_P_sum)\n",
    "\n",
    "print(CM)\n",
    "print(\"Accuracy :\", round(Accuracy,4))\n",
    "print(\"Sensitivity :\", round(sensitivity,4))\n",
    "print(\"Precision :\", round(precision,4))\n",
    "print(\"F1-Measure :\", round(f1_measure,4))\n",
    "print(\"F2-Measure :\", round(fn_measure,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC Score Check (with validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score : 0.8161793879610251\n"
     ]
    }
   ],
   "source": [
    "auc_score = roc_auc_score(validation_org['target'], validation_org['pred_val'])\n",
    "print('AUC Score :', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000    0.004940\n",
       "160001    0.027923\n",
       "160002    0.077302\n",
       "160003    0.136503\n",
       "160004    0.018992\n",
       "160005    0.019176\n",
       "160006    0.009856\n",
       "160007    0.061049\n",
       "160008    0.049936\n",
       "160009    0.061051\n",
       "160010    0.031351\n",
       "160011    0.006619\n",
       "160012    0.044182\n",
       "160013    0.079974\n",
       "160014    0.077037\n",
       "160015    0.208605\n",
       "160016    0.056972\n",
       "160017    0.133358\n",
       "160018    0.022494\n",
       "160019    0.050360\n",
       "160020    0.001307\n",
       "160021    0.038319\n",
       "160022    0.078318\n",
       "160023    0.035448\n",
       "160024    0.040323\n",
       "160025    0.005035\n",
       "160026    0.101433\n",
       "160027    0.000865\n",
       "160028    0.001972\n",
       "160029    0.027642\n",
       "            ...   \n",
       "199970    0.190505\n",
       "199971    0.495408\n",
       "199972    0.104790\n",
       "199973    0.045145\n",
       "199974    0.018430\n",
       "199975    0.001805\n",
       "199976    0.018828\n",
       "199977    0.117282\n",
       "199978    0.062786\n",
       "199979    0.287235\n",
       "199980    0.055603\n",
       "199981    0.196585\n",
       "199982    0.029285\n",
       "199983    0.005112\n",
       "199984    0.000499\n",
       "199985    0.004702\n",
       "199986    0.441849\n",
       "199987    0.000130\n",
       "199988    0.005540\n",
       "199989    0.003014\n",
       "199990    0.167535\n",
       "199991    0.001353\n",
       "199992    0.035064\n",
       "199993    0.003970\n",
       "199994    0.445827\n",
       "199995    0.008285\n",
       "199996    0.007163\n",
       "199997    0.200126\n",
       "199998    0.003004\n",
       "199999    0.001311\n",
       "Name: pred_val, Length: 40000, dtype: float32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_org['pred_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model.predict(X_test)\n",
    "pred = np.array(pred_val > 0.5, dtype = int)\n",
    "\n",
    "submission['pred_val'] = pred_val\n",
    "submission['pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
